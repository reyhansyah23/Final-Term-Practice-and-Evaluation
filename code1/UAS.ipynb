{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UAS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "nrgfZBH3fRil"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFeWbhzIelfU",
        "outputId": "6e5b1f19-e2fd-46ab-ceda-e761594fae7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "path = \"/content/drive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/UAS/code\")"
      ],
      "metadata": {
        "id": "HgH0p6jNe3CE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip list"
      ],
      "metadata": {
        "id": "BEn4__nxBLPp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "V3ZJiYdle66v",
        "outputId": "4ac58649-7cc1-40a0-be80-3dab3ae60947"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/UAS/code'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install tensorflow.contrib.slim"
      ],
      "metadata": {
        "id": "wqj-WoB3fGwI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uninstall Tensorflow v2.7.0 dari google colaboratory untuk direplace dengan Tensorflow v1**"
      ],
      "metadata": {
        "id": "Lflx_lEVbyhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall tensorflow"
      ],
      "metadata": {
        "id": "aq0O-wMRhsor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4a6c04-c59f-43c3-a835-9c32f50b0722"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Tensorflow v1 untuk menjalankan code (Script di bawah hanya support menggunakan TFv1)**"
      ],
      "metadata": {
        "id": "XwlwKxZ4cD8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==1.13.2"
      ],
      "metadata": {
        "id": "hf94eVsrht95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4fce5a-7f61-408b-a759-c14bafa72182"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.13.2\n",
            "  Downloading tensorflow-1.13.2-cp37-cp37m-manylinux1_x86_64.whl (92.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.7 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.12.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.42.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.19.5)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.37.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.10.0.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.2) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.13.2 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HARcDTvdyQ_",
        "outputId": "edd14aef-5a40-4b74-d96b-6f94975f4cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(400)])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NET.py"
      ],
      "metadata": {
        "id": "F-8zz0G6fm65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pada code ini, membuat sebuah fungsi sebagai base model yang akan digunakan**"
      ],
      "metadata": {
        "id": "aAv2uhXSeY_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# author is He Zhao\n",
        "# The time to create is 8:47 PM, 28/11/16\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from Opts import lrelu, resUnit\n",
        "from dataBlocks import DataBlocks\n",
        "# import cPickle\n",
        "import pickle\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
        "bias_initializer = tf.constant_initializer(0.0)\n",
        "\n",
        "\n",
        "def build_data(batchsize):\n",
        "    readpath = open('img.pkl', 'rb')\n",
        "    datapaths = pickle.load(readpath)\n",
        "    db = DataBlocks(data_paths=datapaths, train_valid_ratio=[39, 0], batchsize=batchsize, allow_preload=False)\n",
        "    mask_s = np.load('syn_data/mask.npy')\n",
        "    return db, mask_s\n",
        "   \n",
        "\n",
        "\n",
        "def matTonpy_35():\n",
        "\n",
        "    img = sio.loadmat('test_1To4.mat')['imgAllTest']\n",
        "    gt = sio.loadmat('test_1To4.mat')['gtAllTest']\n",
        "    mask = sio.loadmat('test_1To4.mat')['maskAllTest']\n",
        "\n",
        "    return img, gt, mask\n",
        "\n",
        "def discriminator(image, reuse=False):\n",
        "    n=32\n",
        "    bn = slim.batch_norm\n",
        "    with tf.name_scope(\"disciminator\"):\n",
        "        # original\n",
        "        dis1 = slim.convolution2d(image, n, [4, 4], 2, activation_fn=lrelu,\n",
        "                                  reuse=reuse, scope='d_conv1', weights_initializer=initializer)\n",
        "\n",
        "        dis2 = slim.convolution2d(dis1, 2*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu,\n",
        "                                  reuse=reuse, scope='d_conv2', weights_initializer=initializer)\n",
        "\n",
        "        dis3 = slim.convolution2d(dis2, 4*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu,\n",
        "                                  reuse=reuse, scope='d_conv3', weights_initializer=initializer)\n",
        "\n",
        "        dis4 = slim.convolution2d(dis3, 8*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu,\n",
        "                                  reuse=reuse, scope='d_conv4', weights_initializer=initializer)\n",
        "\n",
        "        dis5 = slim.convolution2d(dis4, 16*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu,\n",
        "                                  reuse=reuse, scope='d_conv5', weights_initializer=initializer)\n",
        "\n",
        "        \n",
        "        d_out_logits = slim.fully_connected(slim.flatten(dis5), 1, activation_fn=None, reuse=reuse, scope='d_out',\n",
        "                                            weights_initializer=initializer)\n",
        "\n",
        "        d_out = tf.nn.sigmoid(d_out_logits)\n",
        "    return d_out, d_out_logits\n",
        "    \n",
        "def generator(image, z):\n",
        "    n = 64\n",
        "    with tf.name_scope(\"generator\"):\n",
        "        # original\n",
        "        e1 = slim.conv2d(image, n, [4, 4], 2, activation_fn=lrelu,\n",
        "                         weights_initializer=initializer)\n",
        "        # 256\n",
        "        e2 = slim.conv2d(lrelu(e1), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                         weights_initializer=initializer)\n",
        "        # 128\n",
        "        e3 = slim.conv2d(lrelu(e2), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                         weights_initializer=initializer)\n",
        "        # 64\n",
        "        e4 = slim.conv2d(lrelu(e3), 8 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                         weights_initializer=initializer)\n",
        "        # 32\n",
        "        e5 = slim.conv2d(lrelu(e4), 8*n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                         weights_initializer=initializer)\n",
        "        # 16\n",
        "        e6 = slim.conv2d(lrelu(e5), 8*n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                         weights_initializer=initializer)\n",
        "        # e1 = slim.conv2d(image, n, [4, 4], 2, activation_fn=lrelu, scope='g_e1_conv',\n",
        "        #                  weights_initializer=initializer, reuse=True)\n",
        "        # # 256\n",
        "        # e2 = slim.conv2d(lrelu(e1), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None, scope='g_e2_conv',\n",
        "        #                  weights_initializer=initializer,reuse=True)\n",
        "        # # 128\n",
        "        # e3 = slim.conv2d(lrelu(e2), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None, scope='g_e3_conv',\n",
        "        #                  weights_initializer=initializer,reuse=True)\n",
        "        # # 64\n",
        "        # e4 = slim.conv2d(lrelu(e3), 8 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None, scope='g_e4_conv',\n",
        "        #                  weights_initializer=initializer,reuse=True)\n",
        "        # # 32\n",
        "        # e5 = slim.conv2d(lrelu(e4), 8*n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None, scope='g_e5_conv',\n",
        "        #                  weights_initializer=initializer,reuse=True)\n",
        "        # # 16\n",
        "        # e6 = slim.conv2d(lrelu(e5), 8*n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None, scope='g_e6_conv',\n",
        "        #                  weights_initializer=initializer,reuse=True)\n",
        "\n",
        "\n",
        "\n",
        "        zP = slim.fully_connected(z, 4 * 4 * n, normalizer_fn=None, activation_fn=lrelu, scope='g_project',\n",
        "                                  weights_initializer=initializer,reuse=True)\n",
        "        zCon = tf.reshape(zP, [-1, 4, 4, n])\n",
        "\n",
        "        gen1 = slim.conv2d_transpose(lrelu(zCon), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                     scope='g_dconv1', weights_initializer=initializer,reuse=True)\n",
        "        # 8\n",
        "        gen1 = tf.concat(3, [gen1, e6])\n",
        "        \n",
        "        gen2 = slim.conv2d_transpose(lrelu(gen1), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                     scope='g_dconv2', weights_initializer=initializer,reuse=True)\n",
        "        # 16\n",
        "        gen2 = tf.concat(3, [gen2, e5])\n",
        "\n",
        "        gen3 = slim.conv2d_transpose(lrelu(gen2), 8 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                     scope='g_dconv3', weights_initializer=initializer,reuse=True)\n",
        "        gen3 = tf.concat(3, [gen3, e4])\n",
        "\n",
        "        # 32\n",
        "        gen6 = slim.conv2d_transpose(tf.nn.relu(gen3), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                     scope='g_dconv6', weights_initializer=initializer,reuse=True)\n",
        "        gen6 = tf.concat(3, [gen6, e3])\n",
        "\n",
        "        # 64\n",
        "        gen7 = slim.conv2d_transpose(tf.nn.relu(gen6), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                     scope='g_dconv7', weights_initializer=initializer,reuse=True)\n",
        "        gen7 = tf.concat(3, [gen7, e2])\n",
        "\n",
        "        # 128\n",
        "        gen8 = slim.conv2d_transpose(tf.nn.relu(gen7), n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                     scope='g_dconv8', weights_initializer=initializer,reuse=True)\n",
        "        # gen8 = tf.nn.dropout(gen8, 0.5)\n",
        "        gen8 = tf.concat([gen8, e1],3)\n",
        "        gen8 = tf.nn.relu(gen8)\n",
        "\n",
        "        # 256\n",
        "        gen_out = slim.conv2d_transpose(gen8, 3, [4, 4], 2, activation_fn=tf.nn.tanh, scope='g_out',\n",
        "                                        weights_initializer=initializer)\n",
        "\n",
        "    return gen_out    \n",
        "    "
      ],
      "metadata": {
        "id": "xLwgG_4kfQro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d07454-9d52-4bf0-9457-19cc32dbfc55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dis1 = slim.convolution2d(img, n, [4, 4], 2, activation_fn=lrelu, weights_initializer=initializer)"
      ],
      "metadata": {
        "id": "RHq00WUUqqzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# author is He Zhao\n",
        "# The time to create is 8:47 PM, 28/11/16\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from Opts import lrelu, resUnit\n",
        "from dataBlocks import DataBlocks\n",
        "# import cPickle\n",
        "import pickle\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
        "bias_initializer = tf.constant_initializer(0.0)\n",
        "\n",
        "\n",
        "def build_data(batchsize):\n",
        "    readpath = open('img.pkl', 'rb')\n",
        "    datapaths = pickle.load(readpath)\n",
        "    db = DataBlocks(data_paths=datapaths, train_valid_ratio=[39, 0], batchsize=batchsize, allow_preload=False)\n",
        "    mask_s = np.load('syn_data/mask.npy')\n",
        "    return db, mask_s\n",
        "   \n",
        "\n",
        "\n",
        "def matTonpy_35():\n",
        "\n",
        "    img = sio.loadmat('test_1To4.mat')['imgAllTest']\n",
        "    gt = sio.loadmat('test_1To4.mat')['gtAllTest']\n",
        "    mask = sio.loadmat('test_1To4.mat')['maskAllTest']\n",
        "\n",
        "    return img, gt, mask\n",
        "\n",
        "def discriminator(image, reuse=False):\n",
        "    n=32\n",
        "    bn = slim.batch_norm\n",
        "    with tf.name_scope(\"disciminator\"):\n",
        "        # original\n",
        "        dis1 = slim.convolution2d(image, n, [4, 4], 2, activation_fn=lrelu,\n",
        "                                  reuse=reuse, weights_initializer=initializer)\n",
        "\n",
        "        dis2 = slim.convolution2d(dis1, 2*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu, weights_initializer=initializer)\n",
        "\n",
        "        dis3 = slim.convolution2d(dis2, 4*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu, weights_initializer=initializer)\n",
        "\n",
        "        dis4 = slim.convolution2d(dis3, 8*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu, weights_initializer=initializer)\n",
        "\n",
        "        dis5 = slim.convolution2d(dis4, 16*n, [4, 4], 2, normalizer_fn=bn, activation_fn=lrelu, weights_initializer=initializer)\n",
        "\n",
        "        \n",
        "        d_out_logits = slim.fully_connected(slim.flatten(dis5), 1, activation_fn=None, reuse=reuse,weights_initializer=initializer)\n",
        "\n",
        "        d_out = tf.nn.sigmoid(d_out_logits)\n",
        "    return d_out, d_out_logits\n",
        "    \n",
        "def generator(image, z):\n",
        "    n = 64\n",
        "    with tf.name_scope(\"generator\"):\n",
        "        # original\n",
        "        e1 = slim.conv2d(image, n, [4, 4], 2, activation_fn=lrelu,\n",
        "                  weights_initializer=initializer)\n",
        "        # 256\n",
        "        e2 = slim.conv2d(lrelu(e1), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                          weights_initializer=initializer)\n",
        "        # 128\n",
        "        e3 = slim.conv2d(lrelu(e2), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                          weights_initializer=initializer)\n",
        "        # 64\n",
        "        e4 = slim.conv2d(lrelu(e3), 8 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                          weights_initializer=initializer)\n",
        "        # 32\n",
        "        e5 = slim.conv2d(lrelu(e4), 8*n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                          weights_initializer=initializer)\n",
        "        # 16\n",
        "        e6 = slim.conv2d(lrelu(e5), 8*n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                          weights_initializer=initializer)\n",
        "\n",
        "\n",
        "\n",
        "        zP = slim.fully_connected(z, 4 * 4 * n, normalizer_fn=None, activation_fn=lrelu, scope='g_project',\n",
        "                          weights_initializer=initializer,reuse=True)\n",
        "        zCon = tf.reshape(zP, [-1, 4, 4, n])\n",
        "\n",
        "        gen1 = slim.conv2d_transpose(lrelu(zCon), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                      scope='g_dconv1', weights_initializer=initializer,reuse=True)\n",
        "        # # 8\n",
        "        gen1 = tf.concat([gen1, e6],3)\n",
        "\n",
        "        gen2 = slim.conv2d_transpose(lrelu(gen1), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                      scope='g_dconv2', weights_initializer=initializer,reuse=tf.AUTO_REUSE)\n",
        "        # 16\n",
        "        gen2 = tf.concat([gen2, e5],3)\n",
        "\n",
        "        gen3 = slim.conv2d_transpose(lrelu(gen2), 8 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                      scope='g_dconv3', weights_initializer=initializer,reuse=tf.AUTO_REUSE)\n",
        "        gen3 = tf.concat([gen3, e4],3)\n",
        "\n",
        "        # 32\n",
        "        gen6 = slim.conv2d_transpose(tf.nn.relu(gen3), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                      scope='g_dconv6', weights_initializer=initializer,reuse=tf.AUTO_REUSE)\n",
        "        gen6 = tf.concat([gen6, e3],3)\n",
        "\n",
        "        # 64\n",
        "        gen7 = slim.conv2d_transpose(tf.nn.relu(gen6), 2 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                      scope='g_dconv7', weights_initializer=initializer,reuse=tf.AUTO_REUSE)\n",
        "        gen7 = tf.concat([gen7, e2],3)\n",
        "\n",
        "        # 128\n",
        "        gen8 = slim.conv2d_transpose(tf.nn.relu(gen7), n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
        "                                      scope='g_dconv8', weights_initializer=initializer,reuse=tf.AUTO_REUSE)\n",
        "        # gen8 = tf.nn.dropout(gen8, 0.5)\n",
        "        gen8 = tf.concat([gen8, e1],3)\n",
        "        gen8 = tf.nn.relu(gen8)\n",
        "\n",
        "        # 256\n",
        "        gen_out = slim.conv2d_transpose(gen8, 3, [4, 4], 2, activation_fn=tf.nn.tanh, scope='g_out',\n",
        "                                        weights_initializer=initializer,reuse=tf.AUTO_REUSE)\n",
        "\n",
        "    return gen_out    \n",
        "    "
      ],
      "metadata": {
        "id": "u3taGd1TpET2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPTS.py"
      ],
      "metadata": {
        "id": "VL5dI7_Uf-V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# author is He Zhao\n",
        "# The time to create is 8:49 PM, 28/11/16\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import scipy.misc\n",
        "import scipy\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "\n",
        "def lrelu(x, leak=0.2, name='lrelu'):\n",
        "    with tf.variable_scope(name):\n",
        "        f1 = 0.5 * (1 + leak)\n",
        "        f2 = 0.5 * (1 - leak)\n",
        "        return f1 * x + f2 * abs(x)\n",
        "\n",
        "def lrelu1(x, leak=0.2, name=\"lrelu\"):\n",
        "    return tf.maximum(x, leak*x)\n",
        "\n",
        "\n",
        "def save_images(images, size, image_path):\n",
        "    return imsave(inverse_transform(images), size, image_path)\n",
        "\n",
        "\n",
        "def merge(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    img = np.zeros((h * size[0], w * size[1], 3))\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % size[1]\n",
        "        j = idx // size[1]\n",
        "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def imsave(images, size, path):\n",
        "    return scipy.misc.imsave(path, merge(images, size))\n",
        "\n",
        "\n",
        "def inverse_transform(images):\n",
        "    return (images+1.)/2.\n",
        "\n",
        "def matTonpy():\n",
        "\n",
        "    # img = sio.loadmat('sample.mat')['imgSample']\n",
        "    # gt = sio.loadmat('sample.mat')['gtSample']\n",
        "\n",
        "    img = sio.loadmat('test.mat')['imgAllTest']\n",
        "    gt = sio.loadmat('test.mat')['gtAllTest']\n",
        "\t\t\n",
        "    # with open('img_sample.npy', 'wb') as fout:\n",
        "    #     np.save(fout, img)\n",
        "    # with open('gt_sample.npy', 'wb') as fout:\n",
        "    #     np.save(fout, gt)\n",
        "    return img, gt\n",
        "\n",
        "\n",
        "def TestImgForTest(dataPath):\n",
        "\n",
        "    img = sio.loadmat(dataPath)['imgAllTest']\n",
        "    gt = sio.loadmat(dataPath)['gtAllTest']\n",
        "\n",
        "    return img, gt\n",
        "\n",
        "\n",
        "def TrainImgForTest(dataPath):\n",
        "\n",
        "    img = sio.loadmat(dataPath)['imgAllTrain']\n",
        "    gt = sio.loadmat(dataPath)['gtAllTrain']\n",
        "\n",
        "    return img, gt\n",
        "\n",
        "def resUnit(input_layer, i, out_size):\n",
        "    with tf.variable_scope(\"g_res_unit\" + str(i)):\n",
        "        net = slim.conv2d(inputs=input_layer, normalizer_fn=slim.batch_norm, activation_fn=lrelu,\n",
        "                          num_outputs=out_size, kernel_size=[4, 4], stride=2, padding='SAME')\n",
        "\n",
        "        net = slim.conv2d(inputs=net, normalizer_fn=slim.batch_norm, activation_fn=lrelu,\n",
        "                          num_outputs=out_size, kernel_size=[4, 4], stride=1, padding='SAME')\n",
        "\n",
        "        res = slim.conv2d(inputs=input_layer, normalizer_fn=slim.batch_norm, activation_fn=lrelu,\n",
        "                          num_outputs=out_size, kernel_size=[1, 1], stride=2, padding='SAME')\n",
        "\n",
        "        output = net + res\n",
        "    return output\n",
        "\n",
        "\n",
        "def resUnit_up(input_layer, i, out_size):\n",
        "    with tf.variable_scope(\"g_res_unit_up\" + str(i)):\n",
        "        net = slim.conv2d_transpose(inputs=input_layer, normalizer_fn=slim.batch_norm, activation_fn=lrelu,\n",
        "                                    num_outputs=out_size, kernel_size=[4, 4], stride=1, padding='SAME')\n",
        "\n",
        "        net = slim.conv2d_transpose(inputs=net, normalizer_fn=slim.batch_norm, activation_fn=lrelu,\n",
        "                                    num_outputs=out_size, kernel_size=[4, 4], stride=2, padding='SAME')\n",
        "\n",
        "        res = slim.conv2d_transpose(inputs=input_layer, normalizer_fn=slim.batch_norm, activation_fn=lrelu,\n",
        "                                    num_outputs=out_size, kernel_size=[1, 1], stride=2, padding='SAME')\n",
        "\n",
        "        output = net + res\n",
        "    return output"
      ],
      "metadata": {
        "id": "vVoMzv46fLGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG.py"
      ],
      "metadata": {
        "id": "7xtRhsfSgGGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code di bawah ini merupakan sebuah fungsi untuk model deep neural network dengan arsitektur VGG**"
      ],
      "metadata": {
        "id": "Ks5cQ2O7t7MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) 2015-2016 Anish Athalye. Released under GPLv3.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import pdb\n",
        "\n",
        "MEAN_PIXEL = np.array([ 123.68 ,  116.779,  103.939])\n",
        "\n",
        "def net(data, input_image):\n",
        "    layers = (\n",
        "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
        "\n",
        "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
        "\n",
        "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
        "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
        "\n",
        "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
        "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
        "\n",
        "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
        "        'relu5_3', 'conv5_4', 'relu5_4'\n",
        "    )\n",
        "\n",
        "    data = scipy.io.loadmat(data_path)\n",
        "    mean = data['normalization'][0][0][0]\n",
        "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
        "    weights = data['layers'][0]\n",
        "\n",
        "    net = {}\n",
        "    current = input_image\n",
        "    for i, name in enumerate(layers):\n",
        "        kind = name[:4]\n",
        "        if kind == 'conv':\n",
        "            kernels, bias = weights[i][0][0][0][0]\n",
        "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
        "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
        "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
        "            bias = bias.reshape(-1)\n",
        "            current = _conv_layer(current, kernels, bias)\n",
        "        elif kind == 'relu':\n",
        "            current = tf.nn.relu(current)\n",
        "        elif kind == 'pool':\n",
        "            current = _pool_layer(current)\n",
        "        net[name] = current\n",
        "\n",
        "    assert len(net) == len(layers)\n",
        "    return net\n",
        "\n",
        "\n",
        "def _conv_layer(input, weights, bias):\n",
        "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
        "            padding='SAME')\n",
        "    return tf.nn.bias_add(conv, bias)\n",
        "\n",
        "\n",
        "def _pool_layer(input):\n",
        "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
        "            padding='SAME')\n",
        "\n",
        "\n",
        "def preprocess(image):\n",
        "    return image - MEAN_PIXEL\n",
        "\n",
        "\n",
        "def unprocess(image):\n",
        "    return image + MEAN_PIXEL"
      ],
      "metadata": {
        "id": "a1P8si1igKaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils.py"
      ],
      "metadata": {
        "id": "bHWS-NkAgR3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Script di bawah ini untuk memanggil input gambar ke dalam model dan melakukan transformasi pada input (gambar)**"
      ],
      "metadata": {
        "id": "AkcRBAbcuOjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.misc, numpy as np, os, sys\n",
        "import imageio\n",
        "\n",
        "def save_img(out_path, img):\n",
        "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "    scipy.misc.imsave(out_path, img)\n",
        "\n",
        "def scale_img(style_path, style_scale):\n",
        "    scale = float(style_scale)\n",
        "    # o0, o1, o2 = scipy.misc.imread(style_path, mode='RGB').shape\n",
        "    o0, o1, o2 = imageio.imread(style_path, mode='RGB').shape\n",
        "    scale = float(style_scale)\n",
        "    new_shape = (int(o0 * scale), int(o1 * scale), o2)\n",
        "    style_target = get_img(style_path, img_size=new_shape)\n",
        "    return style_target\n",
        "\n",
        "def get_img(src, img_size=False):\n",
        "  #  img = scipy.misc.imread(src, mode='RGB') # misc.imresize(, (256, 256, 3))\n",
        "   img = imageio.imread(src)\n",
        "   if not (len(img.shape) == 3 and img.shape[2] == 3):\n",
        "       img = np.dstack((img,img,img))\n",
        "   if img_size != False:\n",
        "       img = scipy.misc.imresize(img, img_size)\n",
        "   return img\n",
        "\n",
        "def exists(p, msg):\n",
        "    assert os.path.exists(p), msg\n",
        "\n",
        "def list_files(in_path):\n",
        "    files = []\n",
        "    for (dirpath, dirnames, filenames) in os.walk(in_path):\n",
        "        files.extend(filenames)\n",
        "        break\n",
        "\n",
        "    return files"
      ],
      "metadata": {
        "id": "CbL0kpAQgNxX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_img(vgg_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEjxAwcfvl1D",
        "outputId": "3e9f5841-5794-4515-d80c-6bfed35e7b25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]],\n",
              "\n",
              "       [[255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255],\n",
              "        [255, 255, 255]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StyleFeature.py"
      ],
      "metadata": {
        "id": "Pxqlmq2LgaRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1sNqLlMkonjm",
        "outputId": "33cd68a5-26d1-474f-ad66-224546e49f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/UAS/code'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg_path = \"/content/drive/My Drive/UAS/2D_Neuron_dataset/NeuB2/Color_GT/39_color.tif\"\n",
        "# from PIL import Image\n",
        "# img = Image.open(vgg_path).convert('L').resize((28, 28), Image.ANTIALIAS)\n",
        "# img = np.array(img)"
      ],
      "metadata": {
        "id": "GyZ_Xt9onyaO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = image.load_img(vgg_path)"
      ],
      "metadata": {
        "id": "EdDkHDhcl9mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# author is He Zhao\n",
        "# The time to create is 3:40 PM, 23/3/17\n",
        "import tensorflow as tf\n",
        "import vgg\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "\n",
        "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
        "CONTENT_LAYER = ('relu4_2',)\n",
        "\n",
        "\n",
        "# vgg_path = 'imagenet-vgg-verydeep-19.mat'\n",
        "vgg_path = \"/content/drive/My Drive/UAS/2D_Neuron_dataset/NeuB2/Color_GT/39_color.tif\"\n",
        "img = Image.open(vgg_path).convert('L').resize((28, 28), Image.ANTIALIAS)\n",
        "img = np.array(img)\n",
        "data = img\n",
        "\n",
        "def get_style_features(image, mask):\n",
        "\n",
        "    image = tf.mul(image+1, 127.5)\n",
        "    image = image*((mask+1)/2)\n",
        "    \n",
        "    if image._shape_as_list()[1] != 512:\n",
        "        image = tf.image.resize_images(image, [512,512])\n",
        "\n",
        "    img_features = {}\n",
        "\n",
        "    #with tf.device('/cpu:0'):\n",
        "\n",
        "    img_pre = vgg.preprocess(image)\n",
        "    net = vgg.net(data, img_pre)\n",
        "\n",
        "    for layer in STYLE_LAYERS:\n",
        "        features = net[layer]\n",
        "        features = tf.reshape(features, shape=[-1, features._shape_as_list()[1]*features._shape_as_list()[2], features._shape_as_list()[3]])[0]\n",
        "        features_T = tf.transpose(features)\n",
        "        gram = tf.matmul(features_T, features) / float(features._shape_as_list()[0]*features._shape_as_list()[1])\n",
        "        img_features[layer] = gram\n",
        "\n",
        "    return img_features\n",
        "    \n",
        "def get_content_features(image,mask):\n",
        "\n",
        "    image = tf.mul(image + 1, 127.5)\n",
        "    image = image*((mask+1)/2)\n",
        "\n",
        "    img_features = {}\n",
        "\n",
        "    if image._shape_as_list()[1] != 512:\n",
        "        image = tf.image.resize_images(image, [512,512])\n",
        "    \n",
        "    #with tf.device('/cpu:0'):\n",
        "\n",
        "    img_pre = vgg.preprocess(image)\n",
        "    net = vgg.net(data, img_pre)\n",
        "\n",
        "    for layer in CONTENT_LAYER:\n",
        "        features = net[layer]\n",
        "        img_features[layer] = features\n",
        "\n",
        "    return img_features\n",
        "\n",
        "\n",
        "def get_style_loss(style_features, img, mask):\n",
        "\n",
        "    img_features = get_style_features(img, mask)      \n",
        "    \n",
        "\n",
        "    style_lossE = 0\n",
        "    for style_layer in STYLE_LAYERS:\n",
        "        coff = float(1.0 / len(STYLE_LAYERS))\n",
        "        img_gram = img_features[style_layer]\n",
        "        style_gram = style_features[style_layer]\n",
        "        style_lossE += coff * tf.reduce_mean(tf.abs(img_gram - style_gram))\n",
        "\n",
        "    style_loss = tf.reduce_mean(style_lossE)\n",
        "\n",
        "    return style_loss\n",
        "    \n",
        "\n",
        "def get_content_loss(img, syn, mask):\n",
        "\n",
        "    img_features = get_content_features(img, mask)\n",
        "    syn_features = get_content_features(syn, mask)\n",
        "\n",
        "    content_lossE = 0\n",
        "    for content_layer in CONTENT_LAYER:\n",
        "        coff = float(1.0 / len(CONTENT_LAYER))\n",
        "        img_content = img_features[content_layer]\n",
        "        syn_content = syn_features[content_layer]\n",
        "        content_lossE += coff * tf.reduce_mean(tf.abs(img_content - syn_content))\n",
        "\n",
        "    content_loss = tf.reduce_mean(content_lossE)\n",
        "\n",
        "    return content_loss\n",
        "\n",
        "\n",
        "def get_tv_loss(img, mask):\n",
        "    img = img*((mask+1)/2)\n",
        "    # x = tf.reduce_sum(tf.abs(img[:, 1:, :, :] - img[:, :-1, :, :]))\n",
        "    # y = tf.reduce_sum(tf.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n",
        "\n",
        "    x = tf.reduce_mean(tf.abs(img[:, 1:, :, :] - img[:, :-1, :, :]))\n",
        "    y = tf.reduce_mean(tf.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n",
        "\n",
        "    return x+y"
      ],
      "metadata": {
        "id": "g9TJPaj6gWXo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt = tf.placeholder(shape=[None, img_size, img_size, 1], dtype=tf.float32)\n",
        "img = tf.placeholder(shape=[None, img_size, img_size, channel], dtype=tf.float32)\n",
        "mask = tf.placeholder(shape=[None, img_size, img_size, 1], dtype=tf.float32)\n",
        "style = tf.placeholder(shape=[None, style_size, style_size, 3],dtype=tf.float32)\n",
        "z = tf.placeholder(shape=[None, z_size], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "0f-KBKpqamQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gt.shape,mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_sa-MUqbKzm",
        "outputId": "0a6f93c9-27eb-4971-d070-b1e4dc4cc903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(?, 512, 512, 1) (?, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train.py"
      ],
      "metadata": {
        "id": "KI70ml-LgoHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.training import training_util\n",
        "import Net\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import StyleFeature\n",
        "import scipy.io as sio\n",
        "import pdb\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "from Opts import save_images, matTonpy\n",
        "# =============================== path set =============================================== #\n",
        "load_model = None#'initial_model'\n",
        "save_model = False\n",
        "\n",
        "# ============================== parameters set ========================================== #\n",
        "#adversarial\n",
        "L1 = 1\n",
        "#style\n",
        "L2 = 10\n",
        "#content\n",
        "L3 = 1\n",
        "#tv\n",
        "L4 = 100\n",
        "#style number\n",
        "style_flag = 'drive'\n",
        "styleNum = 0\n",
        "\n",
        "# ============================== model set ========================================== #\n",
        "# model = 'test'\n",
        "\n",
        "# result_dir = 'Model_and_Result' + '/' + model + ''\n",
        "# sample_directory = result_dir + '/figs'\n",
        "# sample_directory2 = result_dir + '/figs_mask'\n",
        "# # Directory to save sample images from generator in.\n",
        "# model_directory = result_dir + '/models'  # Directory to save trained model to.\n",
        "\n",
        "# if tf.gfile.Exists(result_dir):\n",
        "#     tf.gfile.DeleteRecursively(result_dir)\n",
        "# if not os.path.exists(sample_directory):\n",
        "#     os.makedirs(sample_directory)\n",
        "# if not os.path.exists(sample_directory2):\n",
        "#     os.makedirs(sample_directory2)\n",
        "# if not os.path.exists(model_directory):\n",
        "#     os.makedirs(model_directory)\n",
        "\n",
        "# os.system('cp {} {}'.format(__file__, result_dir))\n",
        "# os.system('cp {} {}'.format('Net.py', result_dir))\n",
        "# os.system('cp {} {}'.format('Opts.py', result_dir))\n",
        "# os.system('cp {} {}'.format('StyleFeature.py', result_dir))\n",
        "\n",
        "# with open(model_directory + '/training_log.txt', 'w') as f:\n",
        "#     f.close()\n",
        "# ============================== parameters set ========================================== #\n",
        "\n",
        "\n",
        "learning_rate = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "batch_size = 1  # Size of image batch to apply at each iteration.\n",
        "max_epoch = 100\n",
        "\n",
        "channel = 3\n",
        "img_size = 512\n",
        "img_x = 512\n",
        "img_y = 512\n",
        "padding_l = 0\n",
        "padding_r = 0\n",
        "padding_t = 0\n",
        "padding_d = 0\n",
        "\n",
        "style_size = 512\n",
        "\n",
        "sample_batch = 4\n",
        "z_size = 400\n",
        "\n",
        "\n",
        "\n",
        "# =============================== model and data definition ================================ #\n",
        "generator = Net.generator\n",
        "discriminator = Net.discriminator\n",
        "\n",
        "build_data = Net.build_data\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "gt = tf.placeholder(shape=[None, img_size, img_size, 1], dtype=tf.float32)\n",
        "img = tf.placeholder(shape=[None, img_size, img_size, channel], dtype=tf.float32)\n",
        "mask = tf.placeholder(shape=[None, img_size, img_size, 1], dtype=tf.float32)\n",
        "style = tf.placeholder(shape=[None, style_size, style_size, 3],dtype=tf.float32)\n",
        "z = tf.placeholder(shape=[None, z_size], dtype=tf.float32)\n",
        "\n",
        "# gt_mask = tf.concat(3, [gt, mask])\n",
        "gt_mask = tf.concat([gt, mask],3)\n",
        "\n",
        "syn = generator(gt_mask, z)\n",
        "\n",
        "real_img_gt = tf.concat(3, [img, gt, mask])\n",
        "fake_syn_gt = tf.concat(3, [syn, gt, mask])\n",
        "\n",
        "Dx, Dx_logits = discriminator(real_img_gt)\n",
        "Dg, Dg_logits = discriminator(fake_syn_gt, reuse=True)\n",
        "\n",
        "db, mask_s = build_data(batch_size)\n",
        "\n",
        "# ============================= loss function and optimizer =============================== #\n",
        "# style_features\n",
        "import vgg\n",
        "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
        "vgg_path = 'imagenet-vgg-verydeep-19.mat'\n",
        "data = sio.loadmat(vgg_path)\n",
        "\n",
        "if style_flag == 'drive':\n",
        "    ss = sio.loadmat('trn20+tst20.mat')['imgAllTrain'][styleNum]\n",
        "elif style_flag == 'messidor':\n",
        "    ss = sio.loadmat('style.mat')['imgAll'][styleNum]\n",
        "elif style_flag == 'stare':\n",
        "    ss = sio.loadmat('stare_original_mask_binary.mat')['imgAll'][styleNum]\n",
        "    \n",
        "ss = (np.reshape(ss, [batch_size, img_size, img_size, 3]) - 0.5) * 2.0\n",
        "ss = np.lib.pad(ss, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)), 'constant',\n",
        "                constant_values=(-1, -1))  # Pad the images so the are 32x32\n",
        "\n",
        "image = (ss + 1) * 127.5\n",
        "\n",
        "style_features = {}\n",
        "style_features_x = {}\n",
        "style_features_y = {}\n",
        "\n",
        "with tf.Graph().as_default(), tf.device('/cpu:0'), tf.Session() as sess:\n",
        "    style_image = tf.placeholder(tf.float32, shape=image.shape, name='style_image')\n",
        "    img_pre = vgg.preprocess(style_image)\n",
        "    net = vgg.net(data, img_pre)\n",
        "\n",
        "    for layer in STYLE_LAYERS:\n",
        "        features = net[layer].eval(feed_dict={style_image:image})\n",
        "        \n",
        "        \n",
        "        features_x = features[:, 1:, :, :] - features[:, :-1, :, :]\n",
        "        features_y = features[:, :, 1:, :] - features[:, :, :-1, :]\n",
        "\n",
        "        features_x = np.reshape(features_x, (-1, features_x.shape[1] * features_x.shape[2], features_x.shape[3]))[0]\n",
        "        features_y = np.reshape(features_y, (-1, features_y.shape[1] * features_y.shape[2], features_y.shape[3]))[0]\n",
        "\n",
        "        gram_x = np.matmul(features_x.T, features_x) / float(features_x.size)\n",
        "        gram_y = np.matmul(features_y.T, features_y) / float(features_y.size)\n",
        "        style_features_x[layer] = gram_x\n",
        "        style_features_y[layer] = gram_y\n",
        "\n",
        "        features = np.reshape(features, (-1, features.shape[1] * features.shape[2], features.shape[3]))[0]\n",
        "\n",
        "        # mean_value = np.mean(features)\n",
        "        # features = features - mean_value\n",
        "\n",
        "        gram = np.matmul(features.T, features) / float(features.size)\n",
        "        style_features[layer] = gram\n",
        "\n",
        "# ============================================================================================#\n",
        "# discriminator loss\n",
        "with tf.name_scope('d_loss'):\n",
        "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(Dx_logits, tf.ones_like(Dx)))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(Dg_logits, tf.zeros_like(Dg)))\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "# generator loss\n",
        "with tf.name_scope('g_loss'):\n",
        "\n",
        "    g_loss_adversarial = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(Dg_logits, tf.ones_like(Dg)))    \n",
        "\n",
        "    g_loss_style = StyleFeature.get_style_loss(style_features, syn, mask)      \n",
        "    g_loss_content = StyleFeature.get_content_loss(img, syn, mask)    \n",
        "   \n",
        "    g_loss_tv = StyleFeature.get_tv_loss(syn, mask)\n",
        "    \n",
        "    g_loss = L1*g_loss_adversarial + L2*g_loss_style + L3*g_loss_content + L4*g_loss_tv \n",
        "\n",
        "    \n",
        "# split the variable for two differentiable function\n",
        "t_vars = tf.trainable_variables()\n",
        "d_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "g_vars = [var for var in t_vars if 'g_' in var.name]\n",
        "\n",
        "# optimizer\n",
        "global_step = tf.Variable(0, trainable=False)\n",
        "with tf.name_scope('train'):\n",
        "    d_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate*0.4).minimize(d_loss, var_list=d_vars, global_step=global_step)\n",
        "    g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "# =============================== summary prepare ============================================= #\n",
        "\n",
        "# write summary\n",
        "Dx_sum = tf.histogram_summary(\"Dx\", Dx)\n",
        "Dg_sum = tf.histogram_summary(\"Dg\", Dg)\n",
        "\n",
        "Dx_sum_scalar = tf.scalar_summary(\"Dx_value\", tf.reduce_mean(Dx))\n",
        "Dg_sum_scalar = tf.scalar_summary(\"Dg_value\", tf.reduce_mean(Dg))\n",
        "\n",
        "syn_sum = tf.image_summary(\"synthesize\", syn)\n",
        "\n",
        "d_loss_real_sum = tf.scalar_summary(\"d_loss_real\", d_loss_real)\n",
        "d_loss_fake_sum = tf.scalar_summary(\"d_loss_fake\", d_loss_fake)\n",
        "d_loss_sum = tf.scalar_summary(\"d_loss\", d_loss)\n",
        "g_loss_sum = tf.scalar_summary(\"g_loss\", g_loss)\n",
        "\n",
        "# g_sum = tf.merge_summary([Dg_sum, syn_sum, d_loss_fake_sum, g_loss_sum])\n",
        "# d_sum = tf.merge_summary([Dx_sum, d_loss_real_sum, d_loss_fake_sum, d_loss_sum])\n",
        "\n",
        "g_sum = tf.merge_summary([Dg_sum_scalar])\n",
        "d_sum = tf.merge_summary([Dx_sum_scalar])\n",
        "\n",
        "# =============================== train phase ============================================= #\n",
        "init = tf.initialize_all_variables()\n",
        "sess = tf.Session()\n",
        "saver = tf.train.Saver(max_to_keep=None)\n",
        "\n",
        "sess.run(init)\n",
        "#writer = tf.train.SummaryWriter(model_directory, sess.graph)\n",
        "\n",
        "# ==================================== save initialization ================================ #\n",
        "if load_model:\n",
        "    ckpt = tf.train.get_checkpoint_state('Model_and_Result/' + load_model + '/models')\n",
        "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "    # saver.save(sess, model_directory + '/model-' + str(0) + '.cptk')\n",
        "    print (\"load saved model and SAVE\")\n",
        "elif save_model:\n",
        "    saver.save(sess, model_directory + '/model-' + str(0) + '.cptk')\n",
        "    print (\"Saved begining Model \")\n",
        "\n",
        "# ==================================== start training ===================================== #\n",
        "stime=time.time()\n",
        "for epoch in xrange(max_epoch):\n",
        "    batchNum = 1\n",
        "\n",
        "    for data_train, _ in db:\n",
        "        for batch in data_train:\n",
        "\n",
        "            ms = mask_s[batchNum-1]\n",
        "            ms = (np.reshape(ms, [batch_size, img_size, img_size, 1]) - 0.5) * 2.0\n",
        "            ms = np.lib.pad(ms, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)), 'constant',\n",
        "                            constant_values=(-1, -1))\n",
        "\n",
        "            z_sample = np.random.normal(0, 0.001, size=[batch_size, z_size]).astype(np.float32)#mean\n",
        "            zs = z_sample\n",
        "\n",
        "            xs, ys = batch  # Draw a sample batch from MNIST dataset.\n",
        "            if xs.shape[0] != batch_size:\n",
        "                continue\n",
        "\n",
        "            # xs = np.transpose(xs, (0, 2, 3, 1))\n",
        "            xs = (np.reshape(xs, [batch_size, img_size, img_size, channel]) - 0.5) * 2.0\n",
        "            xs = np.lib.pad(xs, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)), 'constant',\n",
        "                            constant_values=(-1, -1))  # Pad the images so the are 32x32\n",
        "\n",
        "            # ys = np.transpose(ys, (0, 2, 3, 1))\n",
        "            ys = (np.reshape(ys, [batch_size, img_size, img_size, 1]) - 0.5) * 2.0\n",
        "            ys = np.lib.pad(ys, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)), 'constant',\n",
        "                            constant_values=(-1, -1))  # Pad the images so the are 32x32\n",
        "\n",
        "            ss = sio.loadmat('test_1To4.mat')['imgAllTest'][3]\n",
        "            ss = (np.reshape(ss, [batch_size, img_size, img_size, 3]) - 0.5) * 2.0\n",
        "            ss = np.lib.pad(ss, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)), 'constant',\n",
        "                            constant_values=(-1, -1))  # Pad the images so the are 32x32\n",
        "\n",
        "            feed_dict = {img: xs, gt: ys, z: zs, mask: ms, style: ss}\n",
        "            # Update the discriminator\n",
        "            _, dLoss = sess.run([d_optimizer, d_loss], feed_dict=feed_dict)  \n",
        "\n",
        "            # Update the generator, twice for good measure.\n",
        "            _ = sess.run([g_optimizer], feed_dict=feed_dict)\n",
        "            \n",
        "\n",
        "            _, gLoss, advL, styleL, contL, tvL = sess.run([g_optimizer, g_loss, g_loss_adversarial, g_loss_style, g_loss_content, g_loss_tv], feed_dict=feed_dict) \n",
        "            \n",
        "            print (\"[Epoch: %2d / %2d] [%4d]Gen Loss: %.4f Disc Loss: %.4f, style: %.4f, content: %.4f, adv: %.4f, tv: %.4f\") \\\n",
        "                  % (epoch, max_epoch, batchNum, gLoss, dLoss, styleL, contL, advL, tvL)\n",
        "            with open(model_directory + '/training_log.txt', 'a') as text_file:\n",
        "                text_file.write(\"[Epoch: %2d / %2d] [%4d]Gen Loss: %.4f Disc Loss: %.4f, style: %.4f, content: %.4f, adv: %.4f, tv: %.4f \\n\"% (epoch, max_epoch, batchNum, gLoss, dLoss, styleL, contL, advL, tvL))\n",
        "            batchNum += 1\n",
        "            if training_util.global_step(sess, global_step) % 100 == 0:\n",
        "\n",
        "                img_sample, gt_sample, mask_sample = Net.matTonpy_35()\n",
        "\n",
        "                z2 = np.random.normal(0, 1.0, size=[batch_size, z_size]).astype(np.float32)                \n",
        "\n",
        "                # img_sample = img_sample[:, :, :, 1]\n",
        "                img_sample = (np.reshape(img_sample, [sample_batch, img_x, img_y, channel]) - 0.5) * 2.0\n",
        "                # Pad the images so the are 32x32\n",
        "                img_sample = np.lib.pad(img_sample, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)),\n",
        "                                        'constant', constant_values=(-1, -1))\n",
        "\n",
        "                gt_sample = (np.reshape(gt_sample, [sample_batch, img_x, img_y, 1]) - 0.5) * 2.0\n",
        "                # Pad the images so the are 32x32\n",
        "                gt_sample = np.lib.pad(gt_sample, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)),\n",
        "                                       'constant', constant_values=(-1, -1))\n",
        "\n",
        "                mask_sample = (np.reshape(mask_sample, [sample_batch, img_x, img_y, 1]) - 0.5) * 2.0\n",
        "                # Pad the images so the are 32x32\n",
        "                mask_sample = np.lib.pad(mask_sample, ((0, 0), (padding_l, padding_r), (padding_t, padding_d), (0, 0)),\n",
        "                                        'constant', constant_values=(-1, -1))\n",
        "\n",
        "                z3 = np.random.normal(0, 1.0, size=[batch_size, z_size]).astype(np.float32)\n",
        "                \n",
        "                sa = 0\n",
        "                sb = 1\n",
        "                sc = 2\n",
        "                sd = 3\n",
        "\n",
        "                syn_sample_a, dLreal_val_a, dLfake_val_a = sess.run([syn, Dx, Dg],\n",
        "                                                                    feed_dict={img: [img_sample[sa]], gt: [gt_sample[sa]], z: z2, mask:[mask_sample[sa]]})\n",
        "                syn_sample_b, dLreal_val_b, dLfake_val_b = sess.run([syn, Dx, Dg],\n",
        "                                                                    feed_dict={img: [img_sample[sb]], gt: [gt_sample[sb]], z: z3, mask:[mask_sample[sb]]})\n",
        "                syn_sample_c, dLreal_val_c, dLfake_val_c = sess.run([syn, Dx, Dg],\n",
        "                                                                    feed_dict={img: [img_sample[sc]], gt: [gt_sample[sc]], z: z2, mask:[mask_sample[sc]]})\n",
        "                syn_sample_d, dLreal_val_d, dLfake_val_d = sess.run([syn, Dx, Dg],\n",
        "                                                                    feed_dict={img: [img_sample[sd]], gt: [gt_sample[sd]], z: zs, mask:[mask_sample[sd]]})\n",
        "\n",
        "                syn_sample = np.concatenate((syn_sample_a, syn_sample_b, syn_sample_c,syn_sample_d),axis=0)\n",
        "\n",
        "                syn_sample_am = syn_sample_a * ((mask_sample[sa] + 1) / 2)\n",
        "                syn_sample_bm = syn_sample_b * ((mask_sample[sb] + 1) / 2)\n",
        "                syn_sample_cm = syn_sample_c * ((mask_sample[sc] + 1) / 2)\n",
        "                syn_sample_dm = syn_sample_d * ((mask_sample[sd] + 1) / 2)\n",
        "                syn_sample_m = np.concatenate((syn_sample_am, syn_sample_bm, syn_sample_cm, syn_sample_dm), axis=0)\n",
        "                \n",
        "                dLreal_val = (dLreal_val_a + dLreal_val_b + dLreal_val_c + dLreal_val_d) / 4\n",
        "                dLfake_val = (dLfake_val_a + dLfake_val_b + dLfake_val_c + dLfake_val_d) / 4\n",
        "\n",
        "                # Save sample generator images for viewing training progress.\n",
        "                save_images(np.reshape(syn_sample, [sample_batch, img_x, img_y, channel]),\n",
        "                            [int(np.sqrt(sample_batch)), int(np.sqrt(sample_batch))],\n",
        "                            sample_directory + '/fig' + str(training_util.global_step(sess, global_step)) + '.png')\n",
        "                            \n",
        "                save_images(np.reshape(syn_sample_m, [sample_batch, img_x, img_y, channel]),\n",
        "                            [int(np.sqrt(sample_batch)), int(np.sqrt(sample_batch))],\n",
        "                            sample_directory2 + '/fig' + str(training_util.global_step(sess, global_step)) + '.png')\n",
        "\n",
        "                print (\"[Sample (global_step = %d)] real: %.4f fake: %.4f\" \\\n",
        "                      % (training_util.global_step(sess, global_step), np.mean(dLreal_val), np.mean(dLfake_val)))\n",
        "                with open(model_directory + '/training_log.txt', 'a') as text_file:\n",
        "                    text_file.write(\"[Sample (global_step = %d)] real: %.4f fake: %.4f \\n\"\n",
        "                                    % (training_util.global_step(sess, global_step), np.mean(dLreal_val),\n",
        "                                       np.mean(dLfake_val)))\n",
        "\n",
        "            if training_util.global_step(sess, global_step) % 1000 == 0:\n",
        "                saver.save(sess,\n",
        "                           model_directory + '/model-' + str(training_util.global_step(sess, global_step)) + '.cptk')\n",
        "                print (\"Saved Model %d, time: %.4f\" % (training_util.global_step(sess, global_step), time.time()-stime))\n",
        "\n",
        "             \n",
        "\n",
        "saver.save(sess, model_directory + '/model-' + str(training_util.global_step(sess, global_step)) + '.cptk')\n",
        "print (\"Saved Model %d, time: %.4f\" % (training_util.global_step(sess, global_step), time.time()-stime))\n",
        "\n",
        "sess.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "sVB8VVcVgp3w",
        "outputId": "57efcdbb-fd15-4327-d1a9-15053abe7b96"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 3 in both shapes must be equal, but are 128 and 512. Shapes are [?,8,8,128] and [?,8,8,512].\n\tFrom merging shape 0 with other shapes. for 'generator/concat/concat_dim' (op: 'Pack') with input shapes: [?,8,8,128], [?,8,8,512].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1717d8a53c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mreal_img_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/UAS/code/Net.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(image, z)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                      scope='g_dconv1', weights_initializer=initializer)\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mgen1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         gen2 = slim.conv2d_transpose(lrelu(gen1), 4 * n, [4, 4], 2, normalizer_fn=slim.batch_norm, activation_fn=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1251\u001b[0m       ops.convert_to_tensor(\n\u001b[1;32m   1252\u001b[0m           \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1255\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m   \"\"\"\n\u001b[0;32m-> 1039\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1100\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m   1053\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m-> 1054\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   5446\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5447\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 5448\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   5449\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5450\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimension 3 in both shapes must be equal, but are 128 and 512. Shapes are [?,8,8,128] and [?,8,8,512].\n\tFrom merging shape 0 with other shapes. for 'generator/concat/concat_dim' (op: 'Pack') with input shapes: [?,8,8,128], [?,8,8,512]."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataBlocks.py"
      ],
      "metadata": {
        "id": "GKotNot_g2EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "\n",
        "class DataIterator(object):\n",
        "    def __init__(self, *data, **params):\n",
        "        '''\n",
        "        PARAMS:\n",
        "            fullbatch (bool): decides if the number of examples return after every\n",
        "                              iteration should be always a full batch.\n",
        "        '''\n",
        "        self.data = data\n",
        "        self.batchsize = params['batchsize']\n",
        "        if 'fullbatch' in params:\n",
        "            self.fullbatch = params['fullbatch']\n",
        "        else:\n",
        "            self.fullbatch = False\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.first = 0\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        outs = []\n",
        "        for val in self.data:\n",
        "            outs.append(val[key])\n",
        "        return self.__class__(*outs, batchsize=self.batchsize, fullbatch=self.fullbatch)\n",
        "\n",
        "\n",
        "class SequentialIterator(DataIterator):\n",
        "    '''\n",
        "    batchsize = 3\n",
        "    [0, 1, 2], [3, 4, 5], [6, 7, 8]\n",
        "    '''\n",
        "    def next(self):\n",
        "        if self.fullbatch and self.first+self.batchsize > len(self):\n",
        "            raise StopIteration()\n",
        "        elif self.first >= len(self):\n",
        "            raise StopIteration()\n",
        "\n",
        "        outs = []\n",
        "        for val in self.data:\n",
        "            outs.append(val[self.first:self.first+self.batchsize])\n",
        "        self.first += self.batchsize\n",
        "        return outs\n",
        "\n",
        "\n",
        "class StepIterator(DataIterator):\n",
        "    '''\n",
        "    batchsize = 3\n",
        "    step = 1\n",
        "    [0, 1, 2], [1, 2, 3], [2, 3, 4]\n",
        "    '''\n",
        "    def __init__(self, *data, **params):\n",
        "        super(self, StepIterator).__init__(self, *data, **params)\n",
        "        self.step = params['step']\n",
        "\n",
        "    def next(self):\n",
        "        if self.fullbatch and self.first+self.batchsize > len(self):\n",
        "            raise StopIteration()\n",
        "        elif self.first >= len(self):\n",
        "            raise StopIteration()\n",
        "\n",
        "        outs = []\n",
        "        for val in self.data:\n",
        "            outs.append(val[self.first:self.first+self.batchsize])\n",
        "        self.first += self.step\n",
        "        return outs\n",
        "\n",
        "\n",
        "def np_load_func(path):\n",
        "    with open(path) as fin:\n",
        "        arr = np.load(fin)\n",
        "    return arr\n",
        "\n",
        "\n",
        "class DataBlocks(object):\n",
        "\n",
        "    def __init__(self, data_paths, batchsize=32, load_func=np_load_func, allow_preload=False):\n",
        "        \"\"\"\n",
        "        DESCRIPTION:\n",
        "            This is class for processing blocks of data, whereby dataset is loaded\n",
        "            and unloaded into memory one block at a time.\n",
        "        PARAM:\n",
        "            data_paths (list or list of list): contains list of paths for data loading,\n",
        "                            example:\n",
        "                                [f1a.npy, f1b.npy, f1c.npy]  or\n",
        "                                [(f1a.npy, f1b.npy, f1c.npy), (f2a.npy, f2b.npy, f2c.npy)]\n",
        "            load_func (function): function for loading the data_paths, default to\n",
        "                            numpy file loader\n",
        "            allow_preload (bool): by allowing preload, it will preload the next data block\n",
        "                            while training at the same time on the current datablock,\n",
        "                            this will reduce time but will also cost more memory.\n",
        "        \"\"\"\n",
        "\n",
        "        assert isinstance(data_paths, (list)), \"data_paths is not a list\"\n",
        "        self.data_paths = data_paths\n",
        "        self.batchsize = batchsize\n",
        "        self.load_func = load_func\n",
        "        self.allow_preload = allow_preload\n",
        "        self.q = Queue()\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.files = iter(self.data_paths)\n",
        "        if self.allow_preload:\n",
        "            self.lastblock = False\n",
        "            bufile = next(self.files)\n",
        "            self.load_file(bufile, self.q)\n",
        "        return self\n",
        "\n",
        "\n",
        "    def next(self):\n",
        "        if self.allow_preload:\n",
        "            if self.lastblock:\n",
        "                raise StopIteration\n",
        "\n",
        "            try:\n",
        "                arr = self.q.get(block=True, timeout=None)\n",
        "                self.iterator = SequentialIterator(*arr, batchsize=self.batchsize)\n",
        "                bufile = next(self.files)\n",
        "                p = Process(target=self.load_file, args=(bufile, self.q))\n",
        "                p.start()\n",
        "            except:\n",
        "                self.lastblock = True\n",
        "        else:\n",
        "            fpath = next(self.files)\n",
        "            arr = self.load_file(fpath)\n",
        "            self.iterator = SequentialIterator(*arr, batchsize=self.batchsize)\n",
        "\n",
        "        return self.iterator\n",
        "\n",
        "\n",
        "    def load_file(self, paths, queue=None):\n",
        "        '''\n",
        "        paths (list or str): []\n",
        "        '''\n",
        "        data = []\n",
        "        if isinstance(paths, (list, tuple)):\n",
        "            for path in paths:\n",
        "                data.append(self.load_func(path))\n",
        "        else:\n",
        "            data.append(self.load_func(paths))\n",
        "        if queue:\n",
        "            queue.put(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "    @property\n",
        "    def nblocks(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "\n",
        "class SimpleBlocks(object):\n",
        "\n",
        "    def __init__(self, data_paths, batchsize=32, load_func=np_load_func, allow_preload=False):\n",
        "        \"\"\"\n",
        "        DESCRIPTION:\n",
        "            This is class for processing blocks of data, whereby dataset is loaded\n",
        "            and unloaded into memory one block at a time.\n",
        "        PARAM:\n",
        "            data_paths (list or list of list): contains list of paths for data loading,\n",
        "                            example:\n",
        "                                [f1a.npy, f1b.npy, f1c.npy]  or\n",
        "                                [(f1a.npy, f1b.npy, f1c.npy), (f2a.npy, f2b.npy, f2c.npy)]\n",
        "            load_func (function): function for loading the data_paths, default to\n",
        "                            numpy file loader\n",
        "            allow_preload (bool): by allowing preload, it will preload the next data block\n",
        "                            while training at the same time on the current datablock,\n",
        "                            this will reduce time but will also cost more memory.\n",
        "        \"\"\"\n",
        "\n",
        "        assert isinstance(data_paths, (list)), \"data_paths is not a list\"\n",
        "        self.data_paths = data_paths\n",
        "        self.batchsize = batchsize\n",
        "        self.load_func = load_func\n",
        "        self.allow_preload = allow_preload\n",
        "        self.q = Queue()\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.files = iter(self.data_paths)\n",
        "        if self.allow_preload:\n",
        "            self.lastblock = False\n",
        "            bufile = next(self.files)\n",
        "            self.load_file(bufile, self.q)\n",
        "        return self\n",
        "\n",
        "\n",
        "    def next(self):\n",
        "        if self.allow_preload:\n",
        "            if self.lastblock:\n",
        "                raise StopIteration\n",
        "\n",
        "            try:\n",
        "                arr = self.q.get(block=True, timeout=None)\n",
        "                self.iterator = SequentialIterator(*arr, batchsize=self.batchsize)\n",
        "                bufile = next(self.files)\n",
        "                p = Process(target=self.load_file, args=(bufile, self.q))\n",
        "                p.start()\n",
        "            except:\n",
        "                self.lastblock = True\n",
        "        else:\n",
        "            fpath = next(self.files)\n",
        "            arr = self.load_file(fpath)\n",
        "            self.iterator = SequentialIterator(*arr, batchsize=self.batchsize)\n",
        "\n",
        "        return self.iterator\n",
        "\n",
        "\n",
        "    def load_file(self, paths, queue=None):\n",
        "        '''\n",
        "        paths (list or str): []\n",
        "        '''\n",
        "        data = []\n",
        "        if isinstance(paths, (list, tuple)):\n",
        "            for path in paths:\n",
        "                data.append(self.load_func(path))\n",
        "        else:\n",
        "            data.append(self.load_func(paths))\n",
        "        if queue:\n",
        "            queue.put(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "    @property\n",
        "    def nblocks(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "\n",
        "class DataBlocks(SimpleBlocks):\n",
        "\n",
        "    def __init__(self, data_paths, train_valid_ratio=[5,1], batchsize=32, load_func=np_load_func, allow_preload=False):\n",
        "        \"\"\"\n",
        "        DESCRIPTION:\n",
        "            This is class for processing blocks of data, whereby dataset is loaded\n",
        "            and unloaded into memory one block at a time.\n",
        "        PARAM:\n",
        "            data_paths (list or list of list): contains list of paths for data loading,\n",
        "                            example:\n",
        "                                [f1a.npy, f1b.npy, f1c.npy]  or\n",
        "                                [(f1a.npy, f1b.npy, f1c.npy), (f2a.npy, f2b.npy, f2c.npy)]\n",
        "            load_func (function): function for loading the data_paths, default to\n",
        "                            numpy file loader\n",
        "            allow_preload (bool): by allowing preload, it will preload the next data block\n",
        "                            while training at the same time on the current datablock,\n",
        "                            this will reduce time but will also cost more memory.\n",
        "        \"\"\"\n",
        "\n",
        "        assert isinstance(data_paths, (list)), \"data_paths is not a list\"\n",
        "        self.data_paths = data_paths\n",
        "        self.train_valid_ratio = train_valid_ratio\n",
        "        self.batchsize = batchsize\n",
        "        self.load_func = load_func\n",
        "        self.allow_preload = allow_preload\n",
        "        self.q = Queue()\n",
        "\n",
        "\n",
        "    def next(self):\n",
        "        if self.allow_preload:\n",
        "            if self.lastblock:\n",
        "                raise StopIteration\n",
        "\n",
        "            try:\n",
        "                train, valid = self.q.get(block=True, timeout=None)\n",
        "                self.train_iterator = SequentialIterator(*train, batchsize=self.batchsize)\n",
        "                self.valid_iterator = SequentialIterator(*valid, batchsize=self.batchsize)\n",
        "                bufile = next(self.files)\n",
        "                p = Process(target=self.load_file, args=(bufile, self.q))\n",
        "                p.start()\n",
        "            except:\n",
        "                self.lastblock = True\n",
        "        else:\n",
        "            fpath = next(self.files)\n",
        "            train, valid = self.load_file(fpath)\n",
        "            self.train_iterator = SequentialIterator(*train, batchsize=self.batchsize)\n",
        "            self.valid_iterator = SequentialIterator(*valid, batchsize=self.batchsize)\n",
        "        return self.train_iterator, self.valid_iterator\n",
        "\n",
        "\n",
        "    def load_file(self, paths, queue=None):\n",
        "        '''\n",
        "        paths (list or str): []\n",
        "        '''\n",
        "        train = []\n",
        "        valid = []\n",
        "        if isinstance(paths, (list, tuple)):\n",
        "            for path in paths:\n",
        "                X = self.load_func(path)\n",
        "                num_train = len(X) * self.train_valid_ratio[0] * 1.0 / sum(self.train_valid_ratio)\n",
        "                num_train = int(num_train)\n",
        "                train.append(X[:num_train])\n",
        "                valid.append(X[num_train:])\n",
        "        else:\n",
        "            X = self.load_func(paths)\n",
        "            # np.random.shuffle(X)\n",
        "            num_train = len(X) * self.train_valid_ratio[0] * 1.0 / sum(self.train_valid_ratio)\n",
        "            num_train = int(num_train)\n",
        "            train.append(X[:num_train])\n",
        "            valid.append(X[num_train:])\n",
        "        data = [train, valid]\n",
        "        if queue:\n",
        "            queue.put(data)\n",
        "        return data"
      ],
      "metadata": {
        "id": "7SDP90IFgvaH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C-NfxmD_g5If"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
